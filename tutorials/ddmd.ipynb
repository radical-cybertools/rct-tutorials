{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f680e6",
   "metadata": {},
   "source": [
    "# Asynchronous DeepDriveMD \n",
    "\n",
    "DeepDriveMD (DDMD) is a framework designed to described and execute molecular dynamics (MD) workflow applications. Specifically, DDMD can be used to specify workflows with multiple types of tasks that support the adaptive simulation & machine learning (ML)-driven analysis motif. This motif underlines a class of applications in which the dynamics of molecular systems are simulated by executing an ensamble of simulations, using suitable ML models to analyse the results of that ensamble of simulations and infer suitable starting points for another ensemble of simulations. That simulation-analysis loop is iterated until a predefined convergence is achieved. \n",
    "\n",
    "## Asynchronous execution\n",
    "\n",
    "It is important to note that both simulation and analysis step of the motif can run concurrently. As soon as a simulation ends, another simulation can start while the ML analysis code constantly runs and makes inferences based on the growing set of available simulation results. \n",
    "\n",
    "Asynchronous executions offer better resource utilization compared to executing the same motif synchronously. That is because simulation tasks require more resources than ML-driven analysis tasks, i.e., this motif requires task heterogeneity. In a synchrnous execution, all the simulation tasks execute concurrently. Note that the execution time of the simulations tasks is diffent, progressively creating a waste of available resources while waiting for all the simulation tasks to terminate. Once all the simulation tasks are done, an analysis task runs, occupying few of the available resources.\n",
    "\n",
    "Conversely, in an asynchronous execution, initially all the resources are allocated to the simulations tasks but, progressively, when resources become available they are allocated to either analysis tasks, new simulation tasks or their supporting tasks. This tutorial shows a proof of concept in which 4 types of tasks are asynchronously executed on a static set of available resources. The 4 types of tasks are:\n",
    "\n",
    "- Simulation: simulates the dynamics of a molecule given a set of initial conditions\n",
    "- Aggreagation: aggregates the results of multiple simulations based on a given threshold of amount of needed result data\n",
    "- ML Training: trains a given model on the aggregated results until a given learning threshold is reached\n",
    "- Agent: utilizes the trained ML model to infer the initial conditions for a new simulation task\n",
    "\n",
    "Algorithmically, we can describe the asynchronous execution as follows:\n",
    "\n",
    "- Start MD simulation tasks, use all the available resources.\n",
    "- upon termination of an MD sim task:\n",
    "  - if the aggregation threshold is reached, kill a sim task and launch an Aggregation task;\n",
    "  - else, launch a new sim task.\n",
    "- upon termination of an Aggregation task, launch a ML training task (possibly killing some of the sim tasks if it requires more resource).\n",
    "- upon termination of an ML training task:\n",
    "  - if learning threshold is reached, launch an Agent task;\n",
    "  - else, launch a sim task.\n",
    "- Upon termination of an Agent task, kill all the tasks and goto i.\n",
    "\n",
    "This notebook implements that algorithm, allowing the user to vary the number of tasks and their parameters to produce different degree of concurrent execution. We utilize the RADICAL-Cybertools, a set of middleware components that enables the high-trhoughtput execution of heterogeneous tasks on high performance computing platforms, at scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0718844a",
   "metadata": {},
   "source": [
    "## RADICAL-Cybertools: RADICAL-Pilot (RP) \n",
    "\n",
    "RP is a Python module which can be installed via one of the following package managers **pip**, **conda**, or **spack**. RP is one of the building blocks of the RADICAL-Cybertools (RCT). RP **must** be installed in a virtual environment and **cannot** be installed as a system-wide Python package. \n",
    "\n",
    "It is required to have a **Python** installation of version **3.6+** (tested with **3.6**, **3.7**, **3.8**, **3.9**), RP dependecies will be installed either automatically during the installation process or could be pre-installed beforehand by the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1580ee",
   "metadata": {},
   "source": [
    "## Preparing the Execution Environment\n",
    "\n",
    "As we will be executing this tutorial within a Jupyter notebook, we install RP directly into the notebook kernel via `pip`, but we could also equally use `conda`.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Note:</b> We \"mute\" the output of the cell with `%%capture capt` to not pollute the notebook output.</div>\n",
    "\n",
    "Depending on the execution environment, you may want to use the Spack package or the container provided by Exaworks SDK, or load the module provided by the administrators of the high performance computing (HPC) platform on which you are executing this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1877d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T12:17:48.357841Z",
     "start_time": "2022-11-22T12:17:47.458237Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture capt\n",
    "\n",
    "%pip install radical.pilot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f65de",
   "metadata": {},
   "source": [
    "Currently, EnTK and its runtime system RADICAL-Pilot require a RabbitMQ and MongoDB server. Those serves need to be deployed and made available before using EnTK. Here we set the access parameters for the servers.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Note:</b> The following assumes that:<br>1. you have a shell;<br>2. you export the relevant environment variables;<br>3. you execute the command jupyter notebook from that shell. In that way, the relevant env variables will be read here via os.environ.get('NAME_VARIABLE').</div>\n",
    "\n",
    "First we need to set MongoDB for Radical Pilot. \n",
    "\n",
    "1. You have an account on an existing, publically available MongoDB server: set the relevant server parameters via environment variables _before_ launching this notebook from that shell\n",
    "2. You installed a local MongoDB server: you can use the default parameters already included in the code below.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Warning:</b> Without an accessible MongoDB server this tutorial will fail.</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53195bcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T12:17:52.430749Z",
     "start_time": "2022-11-22T12:17:52.422540Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture capt\n",
    "\n",
    "import os\n",
    "\n",
    "mdb_host = os.environ.get('MDB_SERVER', 'mongodb')\n",
    "mdb_port = os.environ.get('MDB_PORT',   '27017')\n",
    "mdb_name = os.environ.get('MDB_NAME',   'guest')\n",
    "mdb_pswd = os.environ.get('MDB_PSWD',   'guest')\n",
    "mdb_dtbs = os.environ.get('MDB_DTBS',   'default')\n",
    "\n",
    "%env RADICAL_PILOT_DBURL=mongodb://$mdb_name:$mdb_pswd@$mdb_host:$mdb_port/$mdb_dtbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d40bda",
   "metadata": {},
   "source": [
    "First we import Radical Pilot (RP) and Radical Utils (RU) Python modules in our application so to be able to use its API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77692350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T12:17:57.635805Z",
     "start_time": "2022-11-22T12:17:57.340827Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import signal\n",
    "import threading as mt\n",
    "\n",
    "import radical.pilot as rp\n",
    "import radical.utils as ru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31dfd5c",
   "metadata": {},
   "source": [
    "We define a DDMD Python Class as a representation of a general-purpose middleware component. In production, DDMD would be coded as a fully-featured Python module that would then be loaded into the user application to develop a workflow application that uses the Simulation & ML-enabled analysis motif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396cb007",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T12:17:59.795986Z",
     "start_time": "2022-11-22T12:17:59.787028Z"
    }
   },
   "outputs": [],
   "source": [
    "class DDMD(object):\n",
    "\n",
    "    # define task types (used as prefix on task-uid)\n",
    "    TASK_MD_SIM    = 'md_sim'\n",
    "    TASK_AGGREGATE = 'aggregate'\n",
    "    TASK_ML_TRAIN  = 'ml_train'\n",
    "    TASK_AGENT     = 'agent'\n",
    "\n",
    "    TASK_TYPES     = [TASK_MD_SIM, TASK_AGGREGATE, TASK_ML_TRAIN, TASK_AGENT]\n",
    "\n",
    "    # keep track of core usage\n",
    "    cores_used     = 0\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    #\n",
    "    def __init__(self):\n",
    "\n",
    "        # control flow table\n",
    "        self._protocol = {self.TASK_MD_SIM   : self._control_md_sim,\n",
    "                          self.TASK_AGGREGATE: self._control_aggregate,\n",
    "                          self.TASK_ML_TRAIN : self._control_ml_train,\n",
    "                          self.TASK_AGENT    : self._control_agent}\n",
    "\n",
    "        self._glyphs   = {self.TASK_MD_SIM   : '#',\n",
    "                          self.TASK_AGGREGATE: '+',\n",
    "                          self.TASK_ML_TRAIN : '=',\n",
    "                          self.TASK_AGENT    : '*'}\n",
    "\n",
    "        # bookkeeping\n",
    "        self._aggregated     =  0\n",
    "        self._aggregated_max = 64  # aggregation threshold\n",
    "\n",
    "        self._trained        =  0\n",
    "        self._trained_max    = 16  # training threshold\n",
    "\n",
    "        self._cores          = 16  # available resources\n",
    "        self._cores_used     =  0\n",
    "\n",
    "        self._lock           = mt.RLock()\n",
    "        self._tasks          = {ttype: dict() for ttype in self.TASK_TYPES}\n",
    "        self._final_tasks    = list()\n",
    "\n",
    "        # silence RP reporter, use own\n",
    "        os.environ['RADICAL_REPORT'] = 'false'\n",
    "        self._rep = ru.Reporter('ddmd')\n",
    "        self._rep.title('DDMD')\n",
    "\n",
    "        # RP setup\n",
    "        self._session = rp.Session()\n",
    "        self._pmgr    = rp.PilotManager(session=self._session)\n",
    "        self._tmgr    = rp.TaskManager(session=self._session)\n",
    "\n",
    "        pdesc = rp.PilotDescription({'resource': 'local.localhost_test',\n",
    "                                     'runtime' : 30,\n",
    "                                     'cores'   : self._cores})\n",
    "        self._pilot = self._pmgr.submit_pilots(pdesc)\n",
    "\n",
    "        self._tmgr.add_pilots(self._pilot)\n",
    "        self._tmgr.register_callback(self._checked_state_cb)\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    #\n",
    "    def __del__(self):\n",
    "\n",
    "        self.close()\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    #\n",
    "    def close(self):\n",
    "\n",
    "        if self._session is not None:\n",
    "            self._session.close()\n",
    "            self._session = None\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    #\n",
    "    def dump(self, task=None, msg=''):\n",
    "        '''\n",
    "        dump a representation of current task set to stdout\n",
    "        '''\n",
    "\n",
    "        # this assumes one core per task\n",
    "\n",
    "        self._rep.plain('<<|')\n",
    "\n",
    "        idle = self._cores\n",
    "\n",
    "        n     = len(self._tasks[self.TASK_MD_SIM])\n",
    "        idle -= n\n",
    "        self._rep.ok('%s' % self._glyphs[self.TASK_MD_SIM] * n)\n",
    "\n",
    "        n     = len(self._tasks[self.TASK_AGGREGATE])\n",
    "        idle -= n\n",
    "        self._rep.warn('%s' % self._glyphs[self.TASK_AGGREGATE] * n)\n",
    "\n",
    "        n     = len(self._tasks[self.TASK_ML_TRAIN])\n",
    "        idle -= n\n",
    "        self._rep.error('%s' % self._glyphs[self.TASK_ML_TRAIN] * n)\n",
    "\n",
    "        n     = len(self._tasks[self.TASK_AGENT])\n",
    "        idle -= n\n",
    "        self._rep.info('%s' % self._glyphs[self.TASK_AGENT] * n)\n",
    "\n",
    "        self._rep.plain('%s' % '-' * idle +\n",
    "                        '| %4d [%4d]' % (self._cores_used, self._cores))\n",
    "\n",
    "        if task and msg:\n",
    "            self._rep.plain(' %-15s: %s\\n' % (task.uid, msg))\n",
    "        else:\n",
    "            if task:\n",
    "                msg = task\n",
    "            self._rep.plain(' %-15s: %s\\n' % (' ', msg))\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    #\n",
    "    def start(self):\n",
    "        '''\n",
    "        submit initial set of MD similation tasks\n",
    "        '''\n",
    "\n",
    "        self.dump('submit MD simulations')\n",
    "\n",
    "        # reset bookkeeping\n",
    "        self._aggregated = 0\n",
    "        self._trained    = 0\n",
    "        self._cores_used = 0\n",
    "        self._tasks      = {ttype: dict() for ttype in self._protocol}\n",
    "\n",
    "        # run initial batch of MD_SIM tasks (assume one core per task)\n",
    "        self._submit_task(self.TASK_MD_SIM, n=self._cores)\n",
    "\n",
    "        self.dump('started %s md sims' % self._cores)\n",
    "\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    #\n",
    "    def stop(self):\n",
    "\n",
    "        os.kill(os.getpid(), signal.SIGKILL)\n",
    "        os.kill(os.getpid(), signal.SIGTERM)\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    #\n",
    "    def _get_ttype(self, uid):\n",
    "        '''\n",
    "        get task type from task uid\n",
    "        '''\n",
    "\n",
    "        ttype = uid.split('.')[0]\n",
    "\n",
    "        assert ttype in self.TASK_TYPES, 'unknown task type: %s' % uid\n",
    "        return ttype\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    #\n",
    "    def _submit_task(self, ttype, n=1):\n",
    "        '''\n",
    "        submit 'n' new tasks of specified type\n",
    "\n",
    "        NOTE: all tasks are uniform for now: they use a single core and sleep\n",
    "              for a random number (0..3) of seconds.\n",
    "        '''\n",
    "\n",
    "        with self._lock:\n",
    "\n",
    "            tds   = list()\n",
    "            for _ in range(n):\n",
    "                tds.append(rp.TaskDescription({\n",
    "                         'uid'          : ru.generate_id(ttype),\n",
    "                         'cpu_processes': 1,\n",
    "                         'executable'   : '/bin/sh',\n",
    "                         'arguments'    : ['-c', 'sleep %s; echo %s' %\n",
    "                             (int(random.randint(0,30) / 10),\n",
    "                              int(random.randint(0,10) /  1))]}))\n",
    "\n",
    "            tasks  = self._tmgr.submit_tasks(tds)\n",
    "\n",
    "            for task in tasks:\n",
    "                self._register_task(task)\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    #\n",
    "    def _cancel_tasks(self, uids):\n",
    "        '''\n",
    "        cancel tasks with the given uids, and unregister them\n",
    "        '''\n",
    "\n",
    "        uids = ru.as_list(uids)\n",
    "\n",
    "        # FIXME: does not work\n",
    "        self._tmgr.cancel_tasks(uids)\n",
    "\n",
    "        for uid in uids:\n",
    "            ttype = self._get_ttype(uid)\n",
    "            task  = self._tasks[ttype][uid]\n",
    "            self.dump(task, 'cancel [%s]' % task.state)\n",
    "\n",
    "            self._unregister_task(task)\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    #\n",
    "    def _register_task(self, task):\n",
    "        '''\n",
    "        add task to bookkeeping\n",
    "        '''\n",
    "\n",
    "        with self._lock:\n",
    "            ttype = self._get_ttype(task.uid)\n",
    "            self._tasks[ttype][task.uid] = task\n",
    "\n",
    "            cores = task.description['cpu_processes'] \\\n",
    "                  * task.description['cpu_threads']\n",
    "            self._cores_used += cores\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    #\n",
    "    def _unregister_task(self, task):\n",
    "        '''\n",
    "        remove completed task from bookkeeping\n",
    "        '''\n",
    "\n",
    "        with self._lock:\n",
    "\n",
    "            ttype = self._get_ttype(task.uid)\n",
    "\n",
    "            if task.uid not in self._tasks[ttype]:\n",
    "                return\n",
    "\n",
    "            # removed tasks dont consume cores\n",
    "            cores = task.description['cpu_processes'] \\\n",
    "                  * task.description['cpu_threads']\n",
    "            self._cores_used -= cores\n",
    "\n",
    "            # remove task from bookkeeping\n",
    "            self._final_tasks.append(task.uid)\n",
    "            del self._tasks[ttype][task.uid]\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    #\n",
    "    def _state_cb(self, task, state):\n",
    "        '''\n",
    "        act on task state changes according to our protocol\n",
    "        '''\n",
    "\n",
    "        try:\n",
    "            return self._checked_state_cb(task, state)\n",
    "        except Exception as e:\n",
    "            self._rep.error('\\n\\n---------\\nexception caught: %s\\n\\n' % repr(e))\n",
    "            self.stop()\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    #\n",
    "    def _checked_state_cb(self, task, state):\n",
    "\n",
    "        # this cb will react on task state changes.  Specifically it will watch\n",
    "        # out for task completion notification and react on them, depending on\n",
    "        # the task type.\n",
    "\n",
    "      # if state in [rp.TMGR_SCHEDULING] + rp.FINAL:\n",
    "      #     self.dump(task, ' -> %s' % task.state)\n",
    "\n",
    "        # ignore all non-final state transitions\n",
    "        if state not in rp.FINAL:\n",
    "            return\n",
    "\n",
    "        # ignore tasks which were already\n",
    "        if task.uid in self._final_tasks:\n",
    "            return\n",
    "\n",
    "        # lock bookkeeping\n",
    "        with self._lock:\n",
    "\n",
    "            # raise alarm on failing tasks (but continue anyway)\n",
    "            if state == rp.FAILED:\n",
    "                self._rep.error('task %s failed: %s' % (task.uid, task.stderr))\n",
    "                self.stop()\n",
    "\n",
    "            # control flow depends on ttype\n",
    "            ttype  = self._get_ttype(task.uid)\n",
    "            action = self._protocol[ttype]\n",
    "            if not action:\n",
    "                self._rep.exit('no action found for task %s' % task.uid)\n",
    "            action(task)\n",
    "\n",
    "            # remove final task from bookkeeping\n",
    "            self._unregister_task(task)\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    #\n",
    "    def _control_md_sim(self, task):\n",
    "        '''\n",
    "        react on completed MD simulation task\n",
    "        '''\n",
    "\n",
    "        # - upon termination of an MD sim task:\n",
    "        #   - if the aggregation threshold is reached,\n",
    "        #     - launch an Aggregation task\n",
    "        #   - else\n",
    "        #     - launch a new sim task\n",
    "        try:\n",
    "            self._aggregated += int(task.stdout)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if self._aggregated >= self._aggregated_max:\n",
    "            self._aggregated = 0\n",
    "            self.dump(task, 'completed, aggregation full - start aggregate')\n",
    "            self._submit_task(self.TASK_AGGREGATE)\n",
    "        else:\n",
    "            self.dump(task, 'completed, aggregation low  - start md sim')\n",
    "            self._submit_task(self.TASK_MD_SIM)\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    #\n",
    "    def _control_aggregate(self, task):\n",
    "        '''\n",
    "        react on completed aggregation task\n",
    "        '''\n",
    "\n",
    "        # - upon termination of an Aggregation task, launch a ML training task\n",
    "        #   possibly killing some of the sim tasks if it requires more resources\n",
    "\n",
    "        sim_uid = None\n",
    "        while self._cores_used >= self._cores:\n",
    "\n",
    "            if not self._tasks[self.TASK_MD_SIM]:\n",
    "                # we can't free any resources - continue to submit aggregator\n",
    "                break\n",
    "\n",
    "            # kill a sim_task\n",
    "            # FIXME: I think this is wrong: *this* aggregate task just finished\n",
    "            #        anyway and thus there should be space to start a new sim\n",
    "            sim_uid = random.choice(list(self._tasks[self.TASK_MD_SIM].keys()))\n",
    "            self._cancel_tasks(sim_uid)\n",
    "            break\n",
    "\n",
    "        # submit training task\n",
    "        self.dump(task, 'completed, cancel sim %s - start ml train ' % sim_uid)\n",
    "        self._submit_task(self.TASK_ML_TRAIN)\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    #\n",
    "    def _control_ml_train(self, task):\n",
    "        '''\n",
    "        react on completed ML training task\n",
    "        '''\n",
    "        # - upon termination of an ML training task:\n",
    "        #   - if learning threshold is reached\n",
    "        #     - launch an Agent task;\n",
    "        #   - else\n",
    "        #     - launch a sim task\n",
    "\n",
    "        self._trained += int(task.stdout)\n",
    "        if self._trained >= self._trained_max:\n",
    "            self.dump(task, 'completed, training complete - start agent ')\n",
    "            self._submit_task(self.TASK_AGENT)\n",
    "        else:\n",
    "            self.dump(task, 'completed, training incomplete - start md sim ')\n",
    "            self._submit_task(self.TASK_MD_SIM)\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    #\n",
    "    def _control_agent(self, task):\n",
    "        '''\n",
    "        react on completed agent task\n",
    "        '''\n",
    "        # - Upon termination of an Agent task, kill all the tasks and goto i.\n",
    "\n",
    "        to_cancel = list()\n",
    "        for ttype in self._tasks:\n",
    "            to_cancel += list(self._tasks[ttype].keys())\n",
    "\n",
    "        self.dump(task, 'completed, cancel all & restart')\n",
    "        self._cancel_tasks(to_cancel)\n",
    "\n",
    "        # restart execution\n",
    "        # self.start()",
    "        self.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93008de1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T12:18:01.131849Z",
     "start_time": "2022-11-22T12:18:01.127959Z"
    }
   },
   "outputs": [],
   "source": [
    "%set_env RADICAL_LOG_TGT = stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac289f3f",
   "metadata": {},
   "source": [
    "Now we can generate DDMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6099dc3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T12:18:05.184338Z",
     "start_time": "2022-11-22T12:18:05.116044Z"
    }
   },
   "outputs": [],
   "source": [
    "ddmd = DDMD()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d09986",
   "metadata": {},
   "source": [
    "We can run the DDMD by running `start()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdf0026",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T12:18:12.436762Z",
     "start_time": "2022-11-22T12:18:12.430867Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  ddmd.start()\n",
    "\n",
    "  while True:\n",
    "    # ddmd.dump()\n",
    "    time.sleep(1)\n",
    "\n",
    "finally:\n",
    "  ddmd.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rct]",
   "language": "python",
   "name": "conda-env-rct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "f569777653b0bffad19783a3dc21f689c729fd5fa8fd22d04560b57f18bcfec6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
