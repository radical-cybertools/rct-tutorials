{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab06b5a7-a00d-4041-9823-ff15d3b7608f",
   "metadata": {},
   "source": [
    "# Executing Heterogeneous DAG Workflows with Parsl-RP (RPEX)\n",
    "RPEX integrates the powerful runtime engine and workload manager of RADICAL-Pilot with the flexible and parallel workflow manager of Parsl. RPEX offers the best of both worlds by enabling users to run heterogeneous regular and MPI workflows, such as executables and Python functions, within the same environments on different HPC platforms. Users can express and manage these workflows via Parsl.\n",
    "\n",
    "\n",
    "In this tutorial, we will explore the process of creating a Directed Acyclic Graph (DAG) comprising both MPI (Message Passing Interface) tasks and regular tasks using the Parsl API. The execution of the DAG's tasks will be orchestrated through the RPEX executor. This tutorial will demonstrate how to utilize Parsl's data flow manager and RADICAL Pilot's workload manager to achieve concurrent task execution within the DAG.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The tutorial will cover the following key steps:\n",
    "\n",
    "1. **Configuring the RPEX Executor**:\n",
    "    - Setting up the RPEX executor and binding it to the DAG for task execution.\n",
    "\n",
    "\n",
    "2. **Constructing a Heterogeneous DAG**:\n",
    "    - Using Parsl API to define a heterogeneous DAG with both MPI and non-MPI tasks.\n",
    "\n",
    "\n",
    "3. **Executing the DAG**:\n",
    "    - Running the DAG utilizing RPEX on an local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87581288-89f4-41d4-b951-b770a0956196",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"https://airflow.apache.org/docs/apache-airflow/stable/_images/basic-dag.png\" alt=\"my image\" width=\"30%\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dd37fa-7ddb-420b-9ea7-c64110a35818",
   "metadata": {},
   "source": [
    "As a best practice, let's ensure RADICAL-Pilot and Parsl exist in the notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba1877d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T12:17:48.357841Z",
     "start_time": "2022-11-22T12:17:47.458237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: parsl\n",
      "Version: 2024.1.22\n",
      "Summary: Simple data dependent workflows in Python\n",
      "Home-page: https://github.com/Parsl/parsl\n",
      "Author: The Parsl Team\n",
      "Author-email: parsl@googlegroups.com\n",
      "License: Apache 2.0\n",
      "Location: /home/aymen/ve/rpex/lib/python3.8/site-packages\n",
      "Requires: globus-sdk, tblib, paramiko, dill, typeguard, typing-extensions, setproctitle, requests, psutil, six, pyzmq\n",
      "Required-by: \n",
      "==============\n",
      "\n",
      "  python               : /home/aymen/ve/rpex/bin/python3\n",
      "  pythonpath           : \n",
      "  version              : 3.8.10\n",
      "  virtualenv           : /home/aymen/ve/rpex\n",
      "\n",
      "  radical.gtod         : 1.46.0\n",
      "  radical.pilot        : 1.46.1\n",
      "  radical.saga         : 1.42.0-v1.41.0-1-g8da6a9c1@devel\n",
      "  radical.utils        : 1.46.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip show parsl && echo \"==============\" && ! radical-stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d40bda",
   "metadata": {},
   "source": [
    "First, let's import Parsl and RP Python modules in our application, alongside the RadicalPilotExecutor (RPEX) from Parsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6980a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parsl\n",
    "from parsl.config import Config\n",
    "from parsl.app.app import python_app, bash_app\n",
    "from parsl.executors.radical import ResourceConfig\n",
    "from parsl.executors.radical import RadicalPilotExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e3fc27",
   "metadata": {},
   "source": [
    "## Configuring the RPEX Executor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18286edc-a2b5-4f9e-974b-d0d95a627118",
   "metadata": {},
   "source": [
    "RPEX uses `ResourceConfig`, which is a data class that gives the flexibility to define advanced execution constraints for the RADICAL-Pilot runtime system, such as the number of workers and number of CPUs or GPUs per worker and more.\n",
    "\n",
    "For the purpose of this tutorial, we will use `MPI` worker by specifying the `worker_type` parameter for the `ResourceConfig` class instance, which deploys one MPI worker with 4 CPU cores per worker and 0 GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f95b2af9-0e35-4acb-8912-9dcabbb73880",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpex_cfg = ResourceConfig()\n",
    "rpex_cfg.worker_type = 'MPI'\n",
    "rpex_cfg.cores_per_worker = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77664492-89f8-4a56-a4ea-06e32fb5f979",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "⚠️ NOTE:\n",
    "    \n",
    "The ***cores*** on the executor level represent the entire amount of cores for the executor, including the MPI worker. This approach helps to create a clean separation between the number of cores that are used for the MPI workers, which are responsible for the function execution, and other resources that are used for running executable tasks, for example.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b993e402-7e45-4182-81f2-6fe4ee81b46b",
   "metadata": {},
   "source": [
    "Once we create the `ResourceConfig`, we will pass it to the RPEX executor initialization. This will tell the executor to deploy 1 MPI worker with 4 cores and the rest of the 8 cores (4 cores) are left for executable tasks execution if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40ab3613-e5b1-4935-a0fc-a05ddc2125c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(executors=[RadicalPilotExecutor(\n",
    "                           label='rpex-heterogeneous',\n",
    "                           rpex_cfg=rpex_cfg,\n",
    "                           resource='local.localhost',\n",
    "                           runtime=30, cores=8)])\n",
    "\n",
    "radical_executor = config.executors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1cbaf2-aaf5-44b4-995c-09e9c7245605",
   "metadata": {},
   "source": [
    "Now, let's tell Parsl that we want to use the RPEX executor and to do so we invoke the ``load`` function with the designated config of `RadicalPilotExecutor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56b2a59e-cded-43ce-94c0-944b0ea3562f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsl.dataflow.dflow.DataFlowKernel at 0x7f18e47e42b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsl.load(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d21ef-3403-4a85-87b8-9248c42d9287",
   "metadata": {},
   "source": [
    "### Constructing a Heterogeneous DAG\n",
    "\n",
    "Now the executor is started, let's construct the workflow with 1 MPI functions and 3 regular functions as follows:\n",
    "\n",
    "- ``task_a``: MPI function that calacultes the mean in parallel for N lists \n",
    "- ``task_b``, ``task_c``: calaculate the square root of one of the means of ``task_a`` (``task_b`` and ``task_c`` will run concurrently)\n",
    "- ``task_d``: calculate Euler's identity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77692350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T12:17:57.635805Z",
     "start_time": "2022-11-22T12:17:57.340827Z"
    }
   },
   "outputs": [],
   "source": [
    "@python_app\n",
    "def task_a(arrays, comm=None, parsl_resource_specification={}):\n",
    "    \"\"\"\n",
    "    calculates the mean of an array, using MPI\n",
    "    \n",
    "    :param arr: (np.ndarray)\n",
    "    :param comm: (MPI Communicators) if None, MPI.COMM_WORLD\n",
    "    \n",
    "    :return: (np.ndarray or Number) the result of the sum\n",
    "    \"\"\"\n",
    "    import statistics\n",
    "\n",
    "    rank = comm.Get_rank()\n",
    "    size = comm.Get_size()\n",
    "\n",
    "    if size != len(arrays):\n",
    "        raise ValueError(\"Number of passed lists must be equal to number of ranks\")\n",
    "\n",
    "    if rank == 0:\n",
    "        data = arrays[0]\n",
    "        local_mean = statistics.mean(data)\n",
    "    else:\n",
    "        data = arrays[rank]\n",
    "        local_mean = statistics.mean(data)\n",
    "\n",
    "    global_means = comm.gather(local_mean, root=0)\n",
    "\n",
    "    return global_means\n",
    "\n",
    "\n",
    "arrays =  [[6, 7, 8, 9, 10], [16, 17, 18, 19, 20]]\n",
    "\n",
    "mpi_means = task_a(arrays, comm=None,\n",
    "                   parsl_resource_specification={'ranks': 2})\n",
    "\n",
    "means = [m for m in mpi_means.result() if m is not None][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "032e61e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def task_b_and_c(mean, comm=None, parsl_resource_specification={'ranks':1}):\n",
    "    \"\"\"\n",
    "    calaculate the square root of the mean value\n",
    "    \n",
    "    :param mean: int value of mean\n",
    "    \n",
    "    :return: square root of mean\n",
    "    \"\"\"\n",
    "\n",
    "    import math\n",
    "\n",
    "    return math.sqrt(mean)\n",
    "\n",
    "sqrt_b = task_b_and_c(means[0], comm=None)\n",
    "sqrt_c = task_b_and_c(means[1], comm=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101cfe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_b.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ee0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def task_d(b, c, comm=None, parsl_resource_specification={'ranks':1}):\n",
    "    import cmath\n",
    "\n",
    "    # Compute Euler's identity\n",
    "    result = cmath.exp(1j * cmath.pi) + 1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f5f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(task_d(sqrt_b, sqrt_c).result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e198583e",
   "metadata": {},
   "source": [
    "Finally, shutdown the executor, otherwise it will always stays ready to get more tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d044d15-3678-4d0f-9e36-d4bd50664689",
   "metadata": {},
   "outputs": [],
   "source": [
    "radical_executor.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
