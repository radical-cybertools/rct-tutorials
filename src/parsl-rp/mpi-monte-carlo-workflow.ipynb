{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab06b5a7-a00d-4041-9823-ff15d3b7608f",
   "metadata": {},
   "source": [
    "# Executing Heterogeneous DAG Workflows with Parsl-RP (RPEX)\n",
    "\n",
    "RPEX integrates the powerful runtime engine and workload manager of RADICAL-Pilot with the flexible and parallel workflow manager of Parsl. RPEX offers the best of both worlds by enabling users to run heterogeneous regular and ``MPI`` workflows, such as executables and Python functions, within the same environments on different HPC platforms. Users can express and manage these workflows via Parsl.\n",
    "\n",
    "In this tutorial, we will explore creating an ``MPI`` version of the **Monte Carlo workflow** to calculate the value of **PI**, which is similar to the ``non-MPI`` version in Parsl examples [here](https://parsl.readthedocs.io/en/stable/1-parsl-introduction.html#Monte-Carlo-workflow). This will allow us to utilize both MPI (Message Passing Interface) and regular tasks using the Parsl API. The execution of the workflow's tasks will be managed by the RPEX executor.\n",
    "\n",
    "In conclusion, this tutorial will demonstrate how to utilize Parsl's data flow manager and RADICAL Pilot's workload manager to achieve concurrent task execution within the **Monte Carlo workflow**.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "The tutorial will cover the following key steps:\n",
    "\n",
    "1. **Configuring the RPEX Executor**:\n",
    "    - Setting up the RPEX executor and binding it to the DAG for task execution.\n",
    "\n",
    "\n",
    "2. **Constructing a Heterogeneous Monte Carlo workflow**:\n",
    "    - Parsl API and data managementorators to define a heterogeneous workflow with both MPI and non-MPI tasks\n",
    "      of Python functions and executables.\n",
    "\n",
    "\n",
    "3. **Executing the DAG**:\n",
    "    - Running the DAG utilizing RPEX local host."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87581288-89f4-41d4-b951-b770a0956196",
   "metadata": {},
   "source": [
    "#### The serial version of Parsl Pi example that uses the HighThroughPut executor is as follows:\n",
    "\n",
    "- Each `pi` function takes 10 ** 3 points and run in parallel so the total number of processed points are 3,000,000 points.\n",
    "\n",
    "```\n",
    "App Calls   pi(1M)     pi(1M)     pi(1M)\n",
    "               \\         |         /\n",
    "Futures         a        b        c\n",
    "                 \\       |       /\n",
    "App Call            avg_points()   \n",
    "                         |\n",
    "Future               avg_mpi_pi\n",
    "```\n",
    "\n",
    "#### The MPI version of Pi workflow example that we will build and execute in this tutorial is as follows:\n",
    "\n",
    "- Each `mpi_pi` rank takes 10 ** 3 points and run in parallel so the total number of processed points are 3,000,000 points.\n",
    "\n",
    "```\n",
    "App Calls            mpi_pi(3M)\n",
    "                         |        \n",
    "Futures                  a\n",
    "                       / | \\\n",
    "App Call            avg_points()   \n",
    "                         |\n",
    "Future               avg_mpi_pi\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dd37fa-7ddb-420b-9ea7-c64110a35818",
   "metadata": {},
   "source": [
    "First and as a best practice, let's ensure RADICAL-Pilot and Parsl exist in the notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1877d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T12:17:48.357841Z",
     "start_time": "2022-11-22T12:17:47.458237Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip show parsl && echo \"==============\" && ! radical-stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d40bda",
   "metadata": {},
   "source": [
    "let's import Parsl and RP Python modules in our application, alongside the RadicalPilotExecutor (RPEX) from Parsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6980a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parsl\n",
    "import radical.pilot as rp\n",
    "\n",
    "from parsl.config import Config\n",
    "from parsl.app.app import python_app, bash_app\n",
    "from parsl.executors.radical import ResourceConfig\n",
    "from parsl.executors.radical import RadicalPilotExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30d1b23-d6c3-4fdd-8ed5-0d39e0e45a3b",
   "metadata": {},
   "source": [
    "RP has a set of environment variables to control the log level, turn the report on/off, and the animation as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07add6dd-25bb-498b-9693-f9052c7a99a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env RADICAL_LOG_LVL=OFF\n",
    "%env RADICAL_REPORT=TRUE\n",
    "%env RADICAL_REPORT_ANIME=FALSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8bb50a",
   "metadata": {},
   "source": [
    "## Configuring the RPEX Executor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18286edc-a2b5-4f9e-974b-d0d95a627118",
   "metadata": {},
   "source": [
    "RPEX uses `ResourceConfig`, which is a data class that gives the flexibility to define advanced execution constraints for the RADICAL-Pilot runtime system, such as the number of workers and number of CPUs or GPUs per worker and more.\n",
    "\n",
    "For the purpose of this tutorial, we will use `MPI` worker by specifying the `worker_type` parameter for the `ResourceConfig` class instance, which deploys one MPI worker with 4 CPU cores per worker and 0 GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95b2af9-0e35-4acb-8912-9dcabbb73880",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpex_cfg = ResourceConfig()\n",
    "rpex_cfg.worker_type = 'MPI'\n",
    "rpex_cfg.cores_per_worker = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77664492-89f8-4a56-a4ea-06e32fb5f979",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "⚠️ NOTE:\n",
    "    \n",
    "The ***cores*** on the executor level represent the entire amount of cores for the executor, including the MPI worker. This approach helps to create a clean separation between the number of cores that are used for the MPI workers, which are responsible for the function execution, and other resources that are used for running executable tasks, for example.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b993e402-7e45-4182-81f2-6fe4ee81b46b",
   "metadata": {},
   "source": [
    "Once we create the `ResourceConfig`, we will pass it to the RPEX executor initialization. This will tell the executor to deploy 1 MPI worker with 4 cores and the rest of the 8 cores (4 cores) are left for executable tasks execution, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab3613-e5b1-4935-a0fc-a05ddc2125c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(executors=[RadicalPilotExecutor(\n",
    "                           label='rpex-heterogeneous',\n",
    "                           rpex_cfg=rpex_cfg,\n",
    "                           resource='local.localhost_test',\n",
    "                           runtime=30, cores=8)])\n",
    "\n",
    "radical_executor = config.executors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1cbaf2-aaf5-44b4-995c-09e9c7245605",
   "metadata": {},
   "source": [
    "Now, let's tell Parsl that we want to use the RPEX executor and to do so we invoke the ``load`` function with the designated config of `RadicalPilotExecutor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b2a59e-cded-43ce-94c0-944b0ea3562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsl.load(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77692350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T12:17:57.635805Z",
     "start_time": "2022-11-22T12:17:57.340827Z"
    }
   },
   "outputs": [],
   "source": [
    "@python_app\n",
    "def mpi_pi(num_points, comm=None, parsl_resource_specification={'ranks':3}):\n",
    "    \"\"\"\n",
    "    Calculate the PI value of N points in this case (3 Million)\n",
    "    and distribute them across N ranks (3 ranks) so each rank\n",
    "    takes a fair amount of work (1 Million).\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy\n",
    "\n",
    "    rank = comm.Get_rank()\n",
    "    ranks = comm.Get_size()\n",
    "\n",
    "    def compute_pi(samples):\n",
    "        inside = 0\n",
    "        for x, y in samples:\n",
    "            if x**2 + y**2 < 1:\n",
    "                inside += 1\n",
    "\n",
    "        pi = (inside*4 / samples)\n",
    "\n",
    "        return pi\n",
    "\n",
    "\n",
    "    if rank == 0:\n",
    "        N = num_points // ranks\n",
    "        samples = numpy.random.random((ranks, N, 2))\n",
    "    else:\n",
    "        samples = None\n",
    "\n",
    "    samples = comm.scatter(samples, root=0)\n",
    "\n",
    "    # each rank calculates it's own pi and report it back\n",
    "    mypi = compute_pi(samples) / ranks\n",
    "    \n",
    "    return numpy.mean(mypi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f99f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_means = mpi_pi(3 * 10 ** 6, comm=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d5287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bash App that computes the mean of three PI values\n",
    "@bash_app\n",
    "def mean(future_means, stdout='mean_task.stdout',\n",
    "         parsl_resource_specification={'ranks':1, 'mode': rp.TASK_EXECUTABLE}):\n",
    "    \"\"\"\n",
    "    create a python file with the name `mean.py`\n",
    "    and execute it as an executable (python3 mean.py)\n",
    "    \"\"\"\n",
    "    import os\n",
    "    exec_path = os.path.join(os.getcwd(), 'mean.py')\n",
    "    with open(exec_path, 'w') as f:\n",
    "        cmd = f'print (sum({future_means}) / len({future_means}))'\n",
    "        f.write(cmd)\n",
    "\n",
    "    return f'python3 {exec_path}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82671016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean of the three estimates\n",
    "future_mean_pi = mean(future_means)\n",
    "# wait for the mean_pi to finish\n",
    "future_mean_pi.result()\n",
    "!echo \"Average PI value: \" && cat mean_task.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e198583e",
   "metadata": {},
   "source": [
    "Finally, shutdown the executor, otherwise it will always stays ready to get more tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d044d15-3678-4d0f-9e36-d4bd50664689",
   "metadata": {},
   "outputs": [],
   "source": [
    "radical_executor.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
